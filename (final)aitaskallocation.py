# -*- coding: utf-8 -*-
"""(final)AITaskAllocation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jgVmVJGidyOOPeEBlsvB2uQ63_nukbX1
"""

# Install necessary libraries
!pip install pandas numpy scikit-learn streamlit flask

!wget -q -O - ipv4.icanhazip.com

!pip install pandas numpy scikit-learn streamlit flask

!pip install streamlit-sortables

from google.colab import files
uploaded = files.upload()

!pip install firebase-admin


%%writefile app.py
import streamlit as st
import pandas as pd
import plotly.express as px
from sentence_transformers import SentenceTransformer, util
import firebase_admin
from firebase_admin import credentials, db
import re

# Initialize Firebase
if not firebase_admin._apps:
    cred = credentials.Certificate("privatekey.json")
    firebase_admin.initialize_app(cred, {
        'databaseURL': 'https://ai-task-allocation-default-rtdb.firebaseio.com/'
    })

# Streamlit UI Setup
st.set_page_config(page_title="AI Task Allocation", layout="wide")
st.title("🔹 AI Agent for Smart Task Allocation")
st.markdown("### 📌 Upload CSV files to allocate tasks based on skills and workload.")

# Sidebar Settings
st.sidebar.header("⚙ Settings")
min_match_score = st.sidebar.slider("🔍 Minimum Match Score (%)", 0, 100, 50)
max_tasks_per_person = st.sidebar.slider("📊 Max Tasks per Person", 1, 10, 3)

# File Uploaders
st.subheader("📂 Upload Your Data")
task_file = st.file_uploader("Upload Tasks CSV", type="csv")
individual_file = st.file_uploader("Upload Individuals CSV", type="csv")

if task_file and individual_file:
    tasks = pd.read_csv(task_file)
    individuals = pd.read_csv(individual_file)

    # Normalize column names to avoid KeyErrors
    individuals.columns = individuals.columns.str.strip().str.lower()
    tasks.columns = tasks.columns.str.strip().str.lower()

    if "skills" not in individuals.columns:
        st.error("Error: 'Skills' column not found in Individuals CSV. Please check column names.")
    else:
        st.write("### 👥 Individuals Dataset")
        st.dataframe(individuals.head())
        st.write("### 📋 Tasks Dataset")
        st.dataframe(tasks.head())

        # Load BERT model
        model = SentenceTransformer('all-MiniLM-L6-v2')
        individual_embeddings = model.encode(individuals['skills'].astype(str).tolist(), convert_to_tensor=True)
        task_embeddings = model.encode(tasks['required_skills'].astype(str).tolist(), convert_to_tensor=True)
        cosine_scores = util.pytorch_cos_sim(task_embeddings, individual_embeddings)

        # Extract numeric availability from text
        def extract_numeric_availability(value):
            numbers = re.findall(r'\d+', str(value))
            return int(numbers[0]) if numbers else max_tasks_per_person

        # Task Allocation Function
        def allocate_with_balanced_workload(cosine_scores, individuals, tasks):
            allocations = []
            suggestions = []
            workload = {name: 0 for name in individuals["name"]}
            availability = {name: extract_numeric_availability(individuals[individuals["name"] == name]["availability"].values[0]) for name in individuals["name"]}

            for task_idx, task in enumerate(tasks.itertuples()):
                sorted_indices = cosine_scores[task_idx].argsort(descending=True)
                best_match_idx = None

                for idx in sorted_indices.tolist():
                    candidate = individuals.iloc[idx]
                    if workload[candidate["name"]] < min(max_tasks_per_person, availability[candidate["name"]]):
                        best_match_idx = idx
                        break
                    else:
                        st.warning(f"⚠ {candidate['name']} has reached their maximum task limit.")

                if best_match_idx is None:
                    best_match_idx = sorted_indices[0].item()

                best_match_score = float(cosine_scores[task_idx][best_match_idx].item() * 100)
                selected_individual = individuals.iloc[best_match_idx]
                workload[selected_individual["name"]] += 1

                task_data = {
                    "Task": task.task_description,
                    "Assigned To": selected_individual["name"],
                    "Skills Matched": selected_individual["skills"],
                    "Availability": selected_individual["availability"],
                    "Preference": selected_individual.get("preferences", "N/A"),
                    "Match Score (%)": round(best_match_score, 2),
                    "Status": "To Do"
                }
                allocations.append(task_data)

                # AI Suggestions
                top_suggestions = [{
                    "Candidate": individuals.iloc[idx]["name"],
                    "Match Score (%)": round(float(cosine_scores[task_idx][idx].item() * 100), 2)
                } for idx in sorted_indices[:3].tolist()]
                suggestions.append(top_suggestions)

            return pd.DataFrame(allocations), suggestions

        allocation_results, suggestions = allocate_with_balanced_workload(cosine_scores, individuals, tasks)
        st.write("### 📊 AI-Based Task Allocation")
        st.dataframe(allocation_results)

        # Visualization
        fig = px.bar(allocation_results, x="Task", y="Match Score (%)", color="Assigned To", title="Match Score per Task")
        st.plotly_chart(fig)

        # Manual Reassignment
        st.write("### 🔄 Manual Task Reassignment & AI Suggestions")
        updated_allocations = allocation_results.copy()

        for i in range(len(updated_allocations)):
            st.write(f"#### Task: {updated_allocations.iloc[i]['Task']}")
            current_assignee = updated_allocations.iloc[i]["Assigned To"]
            index = int(individuals[individuals["name"] == current_assignee].index[0])

            new_assignee = st.selectbox(
                f"Reassign Task {i+1}",
                individuals["name"].tolist(),
                index=int(index)
            )
            updated_allocations.at[i, "Assigned To"] = new_assignee

            st.write("💡 AI Suggestions:")
            for suggestion in suggestions[i]:
                st.write(f"➡ {suggestion['Candidate']} (Match: {suggestion['Match Score (%)']}%)")

        if st.button("✅ Save Changes"):
            db.reference("/task_allocations").set(updated_allocations.to_dict(orient="records"))
            st.write("### ✅ Updated Task Allocations (Synced in Real-Time)")
            st.dataframe(updated_allocations)
            fig_updated = px.bar(updated_allocations, x="Task", y="Match Score (%)", color="Assigned To", title="Updated Match Score per Task")
            st.plotly_chart(fig_updated)

        # 💬 Team Chat System
        st.write("### 💬 Team Chat System")
        chat_ref = db.reference("/chat")
        chat_messages = chat_ref.get()

        if chat_messages:
            for msg in chat_messages.values():
                st.write(f"{msg['user']}: {msg['message']}")

        new_message = st.text_input("Type a message:")
        if st.button("Send") and new_message:
            chat_ref.push({"user": "User", "message": new_message})
            st.rerun()

        # Download Button
        csv = updated_allocations.to_csv(index=False).encode('utf-8')
        st.download_button("📥 Download Allocation Results", data=csv, file_name="allocations.csv", mime="text/csv")
else:
    st.warning("⚠ Please upload both CSV files to proceed.")



#

!streamlit run app.py & npx localtunnel --port 8501